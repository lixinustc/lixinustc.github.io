<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xin Li</title>

  <meta name="author" content="Xin Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/xin.jpg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xin Li 李鑫</name>
              </p>
              <p>I am currently a Ph.D. Candidate in MOE-Microsoft Key Laboratory of Multimedia Computing and Communication, University of Science and Technology of China (USTC), supervised by  <a href="https://scholar.google.com/citations?user=1ayDJfsAAAAJ&hl=zh-CN">Zhibo Chen</a>. Prior to that, I obtained my  B.S. degree in Department of Electronic Engineering and Information Science from the University of Science and Technology of China (USTC). 
                From Apr. 2021 to Apr. 2022, I was a research intern at Intelligence Media Group of MSRA under the supervision of <a href="https://scholar.google.com/citations?user=XZugqiwAAAAJ&hl=zh-CN">Cuiling Lan</a> and <a href="https://scholar.google.com/citations?user=_cUfvYQAAAAJ&hl=zh-CN">Wenjun Zeng</a>. 
                And now, I am a visiting Ph.D. of Learning and Vision (LV) Lab at the National University of Singapore under the supervision of <a href="https://scholar.google.com/citations?user=w69Buq0AAAAJ&hl=en">Xinchao Wang</a>.  
                My research interests mainly focus on image/video processing, computer vision, and machine learning, causal learning.
              </p>

              <p style="text-align:center">
                <a href="mailto:lixin666@mail.ustc.edu.cn">Email: lixin666@mail.ustc.edu.cn</a> &nbsp;/&nbsp;
<!--                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp-->
<!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp-->
                <a href="https://scholar.google.com/citations?user=sbiY97gAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://github.com/lixinustc">GitHub</a>
                  <!--&nbsp;/&nbsp;
<!--                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp-->
<!--                <a href="https://github.com/jinx-USTC">Github</a> &nbsp/&nbsp-->
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/xin.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading><b>News!!!</b></heading> 
	      <p></p><li><font color="red"><strong>[04/2024] Won the Basic Research Project for Young Students of National Natural Science Foundation of China (Doctoral candidate), PI~</strong></font><p></p>
	      <p></p><li><font color="red"><strong>[03/2024] Won two first prize in CVPR NTIRE2024 Blind Compressed Image Enhancement Challenge and CVPR NTIRE2024 Quality Assessment for AI-Generated Content (AIGC) Challenge~</strong></font><p></p>
	      <p></p><li><font color="red"><strong>[03/2024] Won first prize in the 6th CLIC2022 (Video Perceptual Track) of DCC ~</strong></font><p></p>
	      <p></p><li><font color="red"><strong>[02/2024] Three papers accepted in CVPR2024~</strong></font><p></p>
	      <p></p><li><font color="red"><strong>[02/2024] I am co-organizing the <a href="https://codalab.lisn.upsaclay.fr/competitions/17638">Short-form UGC Video Quality Assessment Challenge</a> jointly with the <a href="https://cvlai.net/ntire/2024/">9th NTIRE Workshop at CVPR 2024</a>~</strong></font><p></p>
              <p></p><li> <font color="red"><strong>[01/2024] Invited as the reviewer for ECCV2024 ~</strong></font><p></p>
              <p></p><li> <font color="red"><strong>[12/2023] Invited as the reviewer for ICML2024 ~</strong></font><p></p>
              <p></p><li> <font color="red"><strong>[12/2023] Awarded IEEE VCIP Best Paper Award ~</strong></font><p></p>
            <p></p><li> <font color="red"><strong>[09/2023] One paper accepted by IEEE TMM 2023 ~</strong></font><p></p>
            <p></p><li> <font color="red"><strong>[09/2023] One paper accepted by NeurIPS2023 ~</strong></font><p></p>
            <p></p><li> <font color="red"><strong>[02/2023] One paper accepted by CVPR2023 (The first paper for cauality-based IR)~</strong></font><p></p>
            <p></p><li> <font color="red"><strong>[11/2022] One paper accepted by AAAI2023 Oral~</strong></font><p></p>
			      <p></p><li> <font color="red"><strong>[10/2022]  Awarded ByteDance Scholarship 2022 （Ten Students in China）~</strong></font><p></p>
			     <p></p><li> <font color="red"><strong>[08/2022]  One paper accepted by ECCV Workshop 2022~</strong></font><p></p>
              <p></p><li> <font color="red"><strong>[07/2022]  Awarded China Scholarship Council (CSC) scholarship~</strong></font><p></p>
              <p></p><li> <font color="red"><strong>[06/2022]  One paper accepted by IEEE TMM 2022~</strong></font><p></p>
              <p></p><li> <font color="red"><strong>[06/2022]  One paper accepted by MICCAI 2022~</strong></font><p></p>
              <p></p><li> <font color="red"><strong>[04/2022] First prize in 5th CVPR CLIC 2022 in Perceptual Metric Track~</strong></font><p></p>
              <p></p></li><li><strong>[11/2021] </strong> One paper accepted by IEEE TIP 2021.<p></p>
              <p></p></li><li><strong>[10/2021] </strong> Awarded China National Scholarship.<p></p>
              <p></p></li><li><strong>[09/2021] </strong> One paper accepted by IEEE TCSVT 2021.<p></p>
              <p></p></li><li><strong>[06/2021] </strong> One paper accepted by IEEE TIP 2021.<p></p>
              <p></p></li><li><strong>[11/2020] </strong> One papers accepted by AAAI 2021.<p></p>
              <p></p></li><li><strong>[08/2020] </strong> One paper accepted by ECCV Workshop 2020.<p></p>
              <p></p></li><li><strong>[06/2020] </strong> Two papers accepted by ECCV 2020.<p></p>
              <p></p></li><li><strong>[03/2020] </strong> One paper accepted by CVPR Workshop 2020.<p></p>
              <p></p></li><li><font color="red"><strong>[01/2020] The third prize in the 2019 4K+HDR National Artificial Intelligence Competition. (3/1000+)<strong></font>.<p></p>
<!--              <p><li><strong>[09/2019] </strong> One paper accepted by NeurIPS 2019.</p>-->
<!--              <p><li><strong>[11/2018] </strong> Awarded the Huawei Scholarship (¥8000).</p>-->
            </li></td>
          </tr>
        </tbody></table>
        
        <heading><b>Publications</b></heading>

      <ul>
        <li><font color="Green"><strong>Latest Works!!!</strong></font>:
        <p></p>
    <ul>
      <li>  <a href="https://arxiv.org/pdf/2309.17014.pdf">FreqAlign: Excavating Perception-oriented Transferability for Blind Image Quality Assessment from A Frequency Perspective</a>. (IEEE TMM 2023) <br> <strong>Xin Li</strong>, Yiting Lu, Zhibo Chen. </li>
      <li>  <a href="https://arxiv.org/abs/2309.13625"> GraphAdapter: Tuning Vision-Language Models With Dual Knowledge Graph </a>. (NeurIPS2023) <br> <strong>Xin Li</strong>, Dongze Lian, Zhihe Lu, Jiawang Bai, Zhibo Chen*, Xinchao Wang*. </li>
       <li>  <a href="https://arxiv.org/abs/2308.09388">Diffusion Models for Image Restoration and Enhancement - A Comprehensive Survey</a>. (Arxiv2023) <br> <strong>Xin Li</strong>, Yulin Ren, Xin Jin, Cuiling Lan, Xingrui Wang, Wenjun Zeng, Xinchao Wang, Zhibo Chen. </li>
       <li>  <a href="https://arxiv.org/pdf/2303.06859.pdf">Learning Distortion Invaraint Representation for Image Restoration from A Causality Perspective</a>. (CVPR2023) <br> <strong>Xin Li</strong>, Bingchen Li, Xin Jin, Cuiling Lan, Zhibo Chen*. </li>
      <a href="https://github.com/lixinustc/Causal-IR-DIL">Code Release</a>
       <li> <a href="https://github.com/lixinustc/Enhance-Anything">Enhance-Anything</a> with the pouplar <a href="https://github.com/lixinustc/Enhance-Anything">Segment-anything (SAM)</a> is started to be developed and released.

      <p></p> 
    </ul>
        <li><strong>Image/Video Compression</strong>:
        <p></p>
    <ul>
      <li> <a href="https://arxiv.org/abs/2106.03511">Task-driven Semantic Coding via Reinforcement Learning</a>. (IEEE TIP2021) <br> <strong>Xin Li</strong>, Jun Shi, Zhibo Chen*. </li>
       <a href="https://github.com/lixinustc/Task-driven-Semantic-Coding-via-RL">Code Release</a>
      <p></p>
			<li><a href="https://arxiv.org/abs/2012.09550">Learned Block-based Hybrid Image Compression</a>. (IEEE TCSVT2021) <br> Yaojun Wu#, <strong>Xin Li# (Equal Contribution)</strong>#, Zhizheng Zhang, Xin Jin, Zhibo Chen*. </li>
			<p></p>					 			
       <li><a href="https://arxiv.org/abs/2208.11529">Hierarchical Reinforcement Learning Based Video Semantic Coding for Segmentation</a>.  (IEEE VCIP2022) <br> Guangqi Xie, <strong>Xin Li</strong>, Shiqi Lin, et al.  </li>
       <p></p>
       <li><a href="https://arxiv.org/abs/2208.11673">Learned Lossless JPEG Transcoding via Joint Lossy and Residual Compression</a> (IEEE VCIP2022) <br> Xiaoshuai Fan, <strong>Xin Li</strong>, Zhibo Chen*. </li>
    </ul>
     <p></p>
			 <li><strong>Image/Video Processing/Restoration</strong>:
			 												 																  <p></p>
    <ul>
      <li> <a href="https://arxiv.org/pdf/2111.13078.pdf">Few-Shot Real Image Restoration via Distortion-Relation Guided Transfer Learning</a>. (Preprint) <br> <strong>Xin Li</strong>, Xin Jin, Jun Fu, Xiaoyuan Yu, Bei Tong, Zhibo Chen*. </li>
      <p></p> 
      <li><a href="https://arxiv.org/pdf/2208.09885.pdf">HST: Hierarchical Swin Transformer for Compressed Image Super-resolution</a>. (ECCV2022-workshop) <br> Bingchen Li, <strong>Xin Li</strong>, Yiting Lu, et. al..  </li>
      <a href="https://github.com/lixinustc/HST-for-Compressed-Image-SR">Code Release</a>
      <p></p>
			<li><a href="https://arxiv.org/abs/2012.06131" data-clk="hl=zh-CN&sa=T&ei=IYz6X9_3B86Ty9YPrrKhqAQ">Learning Omni-frequency Region-adaptive Representations for Real Image Super-Resolution</a>. (AAAI-2021)<br> <strong>Xin Li</strong>, Xin Jin, Tao Yu, Yingxue Pang, Simeng Sun, Zhizheng Zhang, Zhibo Chen*. </li>
																	 <p></p>
      <li><a href="https://ieeexplore.ieee.org/abstract/document/9663408">Dual Prior Learning for Blind and Blended Image Restoration</a>. (TIP2021) <br> Xin Jin, Li Zhang, Chaowei Shan, <strong>Xin Li</strong>, Zhibo Chen* 
      <p></p>
      <li><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123740307.pdf">Learning Disentangled Feature Representation for Hybrid-distorted Image Restoration</a>. (ECCV-2020)<br> <strong>Xin Li</strong>, Xin Jin, Jianxin Lin, Sen Liu, Yaojun Wu, Tao Yu, WeiZhou, Zhibo Chen*.  </li>
      <p></p>
      <li><a href="http://challenge.compression.cc/publications/26/">Multi-scale Grouped Dense Network for VVC Intra Coding</a>. (CVPR-Workshop2020)<br> <strong>Xin Li</strong>, Simeng Sun, Zhizheng Zhang, Zhibo Chen*. </li>
      <p></p>
      <li> <a href="https://arxiv.org/abs/2009.14547">FAN: Frequency Aggregation Network for Real Image Super-resolution</a>. (ECCV-Workshop 2020) <br> Yingxue Pang#, <strong>Xin Li</strong>#, Xin Jin, Yaojun Wu, Jianzhao Liu, Sen Liu, Zhibo Chen*.</li> （# indicates equal contribution）
    </ul>  
    <p></p>
			 <li><strong>Image/Video Quality Assessment</strong>:
			 												 				  <p></p>
      <ul>
       <li><a href="https://openaccess.thecvf.com/content/CVPR2022W/CLIC/papers/Liu_SwinIQA_Learned_Swin_Distance_for_Compressed_Image_Quality_Assessment_CVPRW_2022_paper.pdf">SwinIQA: Learned Swin Distance for Compressed Image Quality Assessment</a>. (CVPR-Workshop2022) <br> Jianzhao Liu, <strong>Xin Li</strong>, Yanding Peng, Tao Yu, Zhibo Chen*. </li>
       <a href="https://github.com/lixinustc/SwinIQA">Code Release</a>
       <p></p>
			 <li> RTN: Reinforced Transformer Network for Coronary CT Angiography Vessel-level Image Quality Assessment</a>. (MICCAI2022)<br> Yiting Lu, Jun Fu, <strong>Xin Li</strong>, et al. </li>
      </ul>
      <p></p>
			<li><strong>Image/Video Quality Assessment & Generalization</strong>:
      <p></p>
      <ul>
      <li> <a href="https://arxiv.org/abs/2207.14489">StyleAM: Perception-Oriented Unsupervised Domain Adaption for Non-reference Image Quality Assessment</a>. (Arxiv version) <br> Yiting Lu#, <strong>Xin Li</strong># (Eqaul contribution), Jianzhao Liu, Zhibo Chen*</li>
      <p></p>
			<li><a href="https://arxiv.org/pdf/2104.14115.pdf">LIQA: Lifelong Blind Image Quality Assessment</a>. (TMM2022)<br> Jianzhao Liu, Wei Zhou, <strong>Xin Li</strong>, Jiahua Xu, Shukun An, Zhibo Chen* 
      <p></p>
			<li><a href="https://arxiv.org/abs/2207.08124">Source-free Unsupervised Domain Adaptation for Blind Image Quality Assessment</a>. (Arxiv version) <br> Jianzhao Liu#, <strong>Xin Li</strong># (Equal Contribution), Shukun An, Zhibo Chen* </li>
      </ul>
    <p></p>
      <li><strong>Image/Video Processing & Generalization</strong>
      <p></p>
      <ul>
      		<li> <a href="https://arxiv.org/abs/2008.08242">LIRA: Lifelong Image Restoration from Unknown Blended Distortions</a>. (ECCV2020) <br> JianZhao Liu, Jianxin Lin, <strong>Xin Li</strong>, WeiZhou, Sen Liu, Zhibo Chen*.</li>  
      </ul>
    <p></p>
      <li> <strong>Causal Learning & Generalization & Data augmentation </strong>
      <p></p>
      <ul>
      <li> <a href="https://arxiv.org/abs/2111.13420">Confounder Identification-free Causal Visual Feature Learning</a>. (Arxiv version)<br> <strong>Xin Li</strong>, Zhizheng Zhang*, Guoqiang We, Cuiling Lan*, Wenjun Zeng, Xin Jin, Zhibo Chen*. </li>
      <li> <a href="https://arxiv.org/abs/2112.02862">SelectAugment: Hierarchical Deterministic Sample Selection for Data Augmentation</a>. (AAAI2023 Oral) <br> Shiqi Lin, ZhiZheng Zhang, <strong>Xin Li</strong>, Wenjun Zeng, Zhibo Chen*.</li>
      </ul>
  </li>
</ul>



<p><strong>Academic Services</strong></p>
<ul>
  <li> Invited as a reviewer/PC member for conferences, including ECCV2024, ICML2024, CVPR2024, ICLR2024, AAAI2024, NeurIPS2023, ICCV2023, ICLR2023 workshop, CVPR2023, AAAI2023, CVPR2022, ECCV2022,  VCIP2020, VCIP2021, VCIP2022,  
    and journals, including TIP, TNNLS, TMM, TCSVT, JSAC.
  </li>
</ul>
<p><strong>Competitions</strong></p>
<ul>
  <li>The first prize in the 5th Workshop and Challenge on Learned Image Compression (Perceptual Metric Track) (CVPR-CLIC2022).</li>
  <li>The third prize in the 2019 4K+HDR National Artificial Intelligence Competition.(<font color="#FF0000">3/1000+</font>)</li>
  <li>The third prize in the NTIRE2020 video deblurring task.</li>
</ul>
<p><strong>Awards</strong></p>
<ul>
  <li>Bytedance Scholarship 2022 (<font color="#FF0000">Ten students in China</font>)</li>
  <li>China Scholarship Council (CSC) scholarship
  <li>China National Scholarship for Graduate Student (2021)</li>
  <li>NeurIPS Scholar Award, 2023
</ul>
<p><strong>Research Experience</strong></p>
<ul>
  <li> Sept. 2019 - Present: Ph.D. Candidate, MOE-Microsoft Key Laboratory of Multimedia Computing and Communication, Mentor: <a href="https://scholar.google.com/citations?user=1ayDJfsAAAAJ&hl=zh-CN">Zhibo Chen</a>. </li>
  <li> Apr. 2021 - Apr. 2022: Research Intern,  Intelligent Multimedia Group, Microsoft Research Asia, Mentor: <a href="https://scholar.google.com/citations?user=XZugqiwAAAAJ&hl=zh-CN">Cuiling Lan</a> and <a href="https://scholar.google.com/citations?user=_cUfvYQAAAAJ&hl=zh-CN">Wenjun Zeng</a>.</li>
  <li> Jan. 2023 - ： CSC Visiting Ph.D., LV label, NUS, Mentor: <a href=https://scholar.google.com/citations?user=w69Buq0AAAAJ&hl=en>Xinchao Wang</a>.</li>  
</ul>

      </td>
    </tr>
  </tbody></table>



</body></html>
